import logging
import json
from typing import List, Optional,Any,Dict
from src.Domain import (
                            ConversationContext,
                            IAgentOrchestratorService,
                            ResponsePackageEntity
                        )
from toon import encode
from .toolExecutorService import ToolExecutor
from src.Infrastructure import OpenAIClient
# from .responseGenerator import ResponseGenerator

logger = logging.getLogger(__name__)

class AgentOrchestratorService:
    def __init__(self):
        self.llm_client = OpenAIClient()
        self.tool_executor = ToolExecutor()
        self.contexts: dict[str, ConversationContext] = {}
        
        self.FLOW_DECISION_PROMPT = """
Voc√™ √© um agente de decis√£o de fluxos transacionais.

## CONTEXTO ATUAL DO FLUXO
{flow_context}

## HIST√ìRICO RECENTE
{recent_messages}

## √öLTIMA MENSAGEM DO USU√ÅRIO
{user_message}

## FERRAMENTAS DISPON√çVEIS
{available_tools}

---

RESPONDA **SOMENTE** COM JSON NO FORMATO:

{{
  "flow_decision": "continue | new_flow | complete | reply",
  "reasoning": "por que essa decis√£o",
  "action": "call_tool | ask_user | reply",
  "tool_name": "nome da tool (se action=call_tool)",
  "tool_params": {{}},
  "resolved_params_update": {{}},
  "next_step": "pr√≥xima etapa do fluxo"
}}

## REGRAS

1. **Quando chamar tools:**
   - Usu√°rio pediu uma a√ß√£o que requer dados externos
   - Voc√™ tem todos os par√¢metros necess√°rios
   - Exemplo: usu√°rio forneceu placa+renavam ‚Üí chame a tool de consulta

2. **Quando pedir ao usu√°rio:**
   - Faltam par√¢metros obrigat√≥rios para a tool
   - Usu√°rio n√£o especificou algo importante

3. **Quando apenas responder:**
   - Conversa√ß√£o casual
   - Confirma√ß√£o de algo j√° feito
   - Esclarecimento

4. **Use resolved_params_update para extrair dados da mensagem**
   - Se usu√°rio disse "placa ABC1234", adicione: {{"placa": "ABC1234"}}
   - Se disse "primeira parcela", adicione: {{"parcela": 1}}

5. **NUNCA invente dados**
   - Se n√£o sabe um par√¢metro, deixe vazio
   - A tool vai validar e retornar erro se necess√°rio

6. **Continue fluxos existentes:**
   - Se h√° fluxo ativo e usu√°rio est√° respondendo no contexto, use "continue"
   - Se mudou completamente de assunto, use "new_flow"
"""

        self.RESPONSE_PROMPT = """
Voc√™ responde no WhatsApp de forma natural e direta.

## CONTEXTO DO FLUXO
{flow_context}

## RESULTADO DA √öLTIMA A√á√ÉO
{action_result}

---

INSTRU√á√ïES:

- M√°ximo 600 caracteres
- Tom natural de WhatsApp
- Se acabou de executar uma ferramenta, use os resultados para responder
- Se dados est√£o faltando, pe√ßa naturalmente
- N√£o repita informa√ß√µes que o usu√°rio j√° deu

**REGRA CR√çTICA**: 
- Se voc√™ executou uma ferramenta com sucesso, COMUNIQUE o resultado
- N√£o pergunte se o usu√°rio quer algo que voc√™ acabou de fazer
- Exemplo: se gerou Pix, diga "Pronto, enviei o Pix!", n√£o "Quer que eu gere?"
- Nunca diga, que j√° j√° vai enviar, pergunte o que ele realmente precisa e EXECUTE

Fale como algu√©m digitando no WhatsApp.
"""
    
    def _get_available_tools_description(self) -> str:
        """Retorna descri√ß√£o leg√≠vel das tools dispon√≠veis"""
        tools = self.tool_executor.get_available_tools()
        
        descriptions = []
        for tool in tools:
            descriptions.append(f"- {tool['name']}: {tool['description']}")
        
        return "\n".join(descriptions)
    
    def __build_flow_decision_messages(
        self, 
        context: ConversationContext, 
        user_message: str
    ) -> List[dict]:
        """Monta mensagens para decis√£o de fluxo"""
        flow_ctx = context.get_flow_context()
        tools_desc = self._get_available_tools_description()
        
        recent = "\n".join([
            f"{msg.role}: {msg.content}" 
            for msg in context.get_recent_messages(limit=5)
        ])
        
        prompt = self.FLOW_DECISION_PROMPT.format(
            flow_context=flow_ctx,
            recent_messages=recent,
            user_message=user_message,
            available_tools=tools_desc
        )
        
        return [{"role": "system", "content": prompt}]
    
    def __build_response_messages(
        self, 
        context: ConversationContext,
        action_result: str = "Nenhuma a√ß√£o executada ainda"
    ) -> List[dict]:
        """Monta mensagens para gera√ß√£o de resposta"""
        flow_ctx = context.get_flow_context()
        
        messages = [
            {
                "role": "system", 
                "content": self.RESPONSE_PROMPT.format(
                    flow_context=flow_ctx,
                    action_result=action_result
                )
            }
        ]
        
        for msg in context.get_recent_messages(limit=15):
            messages.append({"role": msg.role, "content": msg.content})
        
        return messages
    
    def __get_or_create_context(self, sender_id: str) -> ConversationContext:
        if sender_id not in self.contexts:
            self.contexts[sender_id] = ConversationContext(sender_id=sender_id)
        return self.contexts[sender_id]
    
    def _should_start_flow(self, message: str, context: ConversationContext) -> bool:
        """
        Heur√≠stica simples: se usu√°rio pede algo que n√£o √© s√≥ conversa,
        inicia fluxo gen√©rico
        """
        if context.active_flow:
            return False
        
        # Keywords que indicam pedido de servi√ßo
        service_keywords = [
            "quero", "preciso", "pode", "me ajuda", "gostaria",
            "emitir", "gerar", "consultar", "verificar", "pagar"
        ]
        
        message_lower = message.lower()
        return any(kw in message_lower for kw in service_keywords)
    
    def _fill_params_from_context(
        self, 
        tool_params: Dict[str, Any],
        resolved_params: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Preenche par√¢metros vazios/None com valores do contexto
        """
        filled = tool_params.copy()
        
        for key, value in filled.items():
            # Se o par√¢metro est√° vazio e existe no contexto, usa do contexto
            if value is None or value == "":
                if key in resolved_params:
                    filled[key] = resolved_params[key]
        
        return filled
    
    async def process_message(self, sender_id: str, message: str):
        """Processa mensagem de forma gen√©rica"""
        
        context = self.__get_or_create_context(sender_id)
        context.add_message("user", message)
        
        logger.info(f"[{sender_id}] üì® Mensagem: {message}")
        
        # ‚úÖ Detecta in√≠cio de fluxo (gen√©rico)
        if self._should_start_flow(message, context):
            context.start_flow("user_request")
            logger.info(f"[{sender_id}] üÜï Fluxo iniciado")
        
        if context.active_flow:
            logger.info(f"[{sender_id}] üìä Flow: {context.active_flow.primary_intent} | Step: {context.active_flow.current_step}")
        
        response_package = ResponsePackageEntity()
        
        # ========== 1. DECIS√ÉO ==========
        decision_messages = self.__build_flow_decision_messages(context, message)
        
        decision_response = await self.llm_client.chat(
            messages=decision_messages,
            tools=None  # N√£o usa function calling aqui, s√≥ JSON
        )
        
        try:
            decision = json.loads(decision_response.get("content", "{}"))
        except json.JSONDecodeError:
            logger.error(f"[{sender_id}] ‚ùå Decis√£o inv√°lida: {decision_response.get('content')}")
            decision = {"flow_decision": "reply", "action": "reply"}
        
        logger.info(f"[{sender_id}] üß† Decis√£o: {decision.get('flow_decision')} | A√ß√£o: {decision.get('action')}")
        
        # ========== 2. ATUALIZA FLUXO ==========
        
        if decision["flow_decision"] == "new_flow":
            context.start_flow(decision.get("intent", "user_request"))
            logger.info(f"[{sender_id}] üÜï Novo fluxo iniciado")
        
        elif decision["flow_decision"] == "continue":
            if not context.active_flow:
                context.start_flow("user_request")
            
            # ‚úÖ GEN√âRICO: atualiza qualquer par√¢metro que o LLM extraiu
            updates = decision.get("resolved_params_update", {})
            for key, value in updates.items():
                context.active_flow.add_resolved_param(key, value)
                logger.info(f"[{sender_id}] ‚úÖ Param: {key} = {value}")
            
            # ‚úÖ Atualiza step se LLM especificou
            next_step = decision.get("next_step")
            if next_step:
                context.active_flow.current_step = next_step
                logger.info(f"[{sender_id}] üìç Step: {next_step}")
        
        elif decision["flow_decision"] == "complete":
            context.complete_flow()
            logger.info(f"[{sender_id}] ‚úÖ Fluxo completo")
        
        # ========== 3. EXECUTA TOOL (GEN√âRICO) ==========
        
        action_result = "Nenhuma a√ß√£o executada"
        
        if decision.get("action") == "call_tool":
            tool_name = decision.get("tool_name")
            tool_params = decision.get("tool_params", {})
            
            if not tool_name:
                logger.error(f"[{sender_id}] ‚ùå action=call_tool mas tool_name vazio")
            else:
                # ‚úÖ PREENCHE PARAMS DO CONTEXTO (gen√©rico)
                if context.active_flow:
                    tool_params = self._fill_params_from_context(
                        tool_params,
                        context.active_flow.resolved_params
                    )
                
                logger.info(f"[{sender_id}] üîß Executando: {tool_name}")
                logger.info(f"[{sender_id}] üìã Params: {tool_params}")
                
                try:
                    # ‚úÖ EXECUTA A TOOL
                    tool_results = await self.tool_executor.execute_tools([{
                        "name": tool_name,
                        "parameters": tool_params
                    }])
                    
                    context.tool_results.extend(tool_results)
                    
                    # ‚úÖ PROCESSA RESULTADOS (GEN√âRICO)
                    for result in tool_results:
                        result_data = result.get("result", {})
                        
                        logger.info(f"[{sender_id}] üì¶ Result keys: {list(result_data.keys())}")
                        
                        # ‚úÖ GEN√âRICO: salva tudo que a tool retornou
                        if context.active_flow:
                            for key, value in result_data.items():
                                # N√£o sobrescreve par√¢metros j√° definidos
                                if key not in context.active_flow.resolved_params:
                                    context.active_flow.add_resolved_param(key, value)
                        
                        # ‚úÖ Extrai arquivos (PDF, imagens, etc)
                        if result_data.get("pdf_path"):
                            response_package.add_document(
                                path=result_data["pdf_path"],
                                caption=result_data.get("pdf_caption", "Documento")
                            )
                            logger.info(f"[{sender_id}] üìÑ PDF: {result_data['pdf_path']}")
                        
                        if result_data.get("image_path"):
                            response_package.add_document(
                                path=result_data["image_path"],
                                caption=result_data.get("image_caption", "Imagem")
                            )
                    
                    action_result = f"Tool '{tool_name}' executada com sucesso. Resultados: {json.dumps(tool_results, ensure_ascii=False)}"
                    logger.info(f"[{sender_id}] ‚úÖ Tool executada")
                
                except Exception as e:
                    logger.error(f"[{sender_id}] ‚ùå Erro na tool: {str(e)}")
                    action_result = f"Erro ao executar '{tool_name}': {str(e)}"
        
        # ========== 4. GERA RESPOSTA ==========
        
        response_messages = self.__build_response_messages(context, action_result)
        
        final_response = await self.llm_client.chat(messages=response_messages)
        answer = final_response["content"]
        
        # ========== 5. FINALIZA√á√ÉO ==========
        
        response_package.text = answer
        context.add_message("assistant", answer)
        
        logger.info(f"[{sender_id}] üí¨ Resposta: {answer[:100]}...")
        
        return response_package